---
title = "Redline System: Adaptive Procedure Matching"
authors = "Andrew Lyjak, Claude Code"
last_updated = "2025-10-27"
status = "Draft"
version = "0.1"
dependencies = [ "dwelling_point_design.md (v0.1)", "action_interface.md (v0.1)", "intention_lattice.md (v0.1)", "procedures.md (v0.1)", "procedure_engine.md (v0.1)",]
---
# Redline System: Adaptive Procedure Matching

## Purpose

The **redline system** bridges template procedures to participant reality through probabilistic matching and adaptive learning. It solves the core problem: **Template procedures specify idealized behavior, but participants exhibit systematic variations.**

**Role in Architecture:** The redline system is the learning layer between:
- **Input:** Observed event streams (Infimum+1: `action_detected`, `participant_response`)
- **Templates:** Procedure specifications (Infimum+2: lattice nodes with `procedure` blocks)
- **Output:** Confidence-scored procedure matches that evolve with participant behavior

**Name Origin:** Like editorial redlines that mark revisions on drafts, the redline system marks the delta between template and reality, making learned variations explicit and actionable.

## Core Concepts

### Template vs. Reality Gap

**Template (idealized):**
```toml
[procedure]
[[procedure.steps]]
type = "action"
id = "act_wake_up"

[[procedure.steps]]
type = "action"
id = "act_coffee"
duration_minutes = [ 5, 10,]

[[procedure.steps]]
type = "action"
id = "act_shower"

[[procedure.steps]]
type = "action"
id = "act_commute"
```

**Reality (participant-specific):**
```
Events: wake_up (7:30) → coffee (7:45, 15min) → commute (8:05)
Missing: shower (skipped 60% of the time)
```

**Redline (learned adaptation):**
```
- Step "shower" is optional (skip_probability: 0.60)
- Step "coffee" duration: learned_mean=15min (template=7.5min)
- Match confidence: 0.78 (strong but not perfect)
```

### The Three Redline Problems

1. **Dwelling Point Label Resolution:** Anonymous IDs → semantic labels
2. **Procedure Matching:** Event sequences → procedure hypotheses
3. **Lattice Promotion:** Learned SQLite diffs → permanent lattice nodes

## Architecture: Semantic Label Resolution

A core function of the Noet architecture is to map the raw, anonymous IDs generated by observation producers (e.g., `dwelling_point_id: "dp_7a3f9b2c"`) to the human-readable, semantic labels used in Intention Lattice templates (e.g., `to_semantic_labels: ["home"]`).

This responsibility has been centralized in the **Action Inference Engine**. For a complete specification of the **Semantic Label Map**, the crawling process, and the user calibration workflow, please see the relevant section in `action_inference_engine.md`.

The Redline System is a primary consumer of this map, using it to resolve location hints in procedures before performing probabilistic matching.

## Architecture: Probabilistic Procedure Matching

### Problem Statement

Event streams exhibit systematic deviations from templates:
- **Reordering:** Steps occur in different sequence
- **Omission:** Steps are skipped (shortcuts, forgetting)
- **Addition:** Extra steps inserted (personalization)
- **Modification:** Step parameters differ (duration, location)

### Matching Contract

**Input:**
- `event_stream`: Chronological list of `action_detected` events (Infimum+1)
- `template_procedure`: Procedure specification from lattice node (Infimum+2)
- `learned_params`: Participant-specific adaptations from previous runs (SQLite)

**Output:**
```rust
pub struct ProcedureMatch {
    pub procedure_id: String,          // Lattice node ID
    pub confidence: f64,               // 0.0-1.0, calibrated probability
    pub matched_events: Vec<String>,   // event_ids that matched steps
    pub skipped_steps: Vec<usize>,     // Step indices with no match
    pub extra_events: Vec<String>,     // event_ids not in template
    pub start_time: String,            // ISO 8601, first matched event
    pub end_time: String,              // ISO 8601, last matched event
    pub match_quality: MatchQuality,   // Enum: Exact | Close | Loose
}

pub enum MatchQuality {
    Exact,   // All steps matched in order
    Close,   // Minor reordering or 1 skip
    Loose,   // Significant deviations but recognizable
}
```

**Validation Rules:**
- `confidence` MUST be in range [0.0, 1.0]
- `matched_events` MUST reference valid event_ids in event log
- `skipped_steps` indices MUST be valid for template procedure
- `start_time` MUST be ≤ `end_time`

### Matching Algorithm (Conceptual)

```python
def match_procedure(event_stream: List[Event],
                   template: Procedure,
                   learned: LearnedParameters) -> Optional[ProcedureMatch]:
    """
    Probabilistic matching with learned tolerances.

    Algorithm outline (implementation-specific):
        1. Window selection: Find time windows where first step could occur
        2. Step matching: For each template step, search for compatible events
        3. Scoring: Compute match quality based on:
           - Matched step ratio
           - Ordering similarity (e.g., Kendall tau distance)
           - Duration fit (within learned variance)
           - Location fit (resolved dwelling points)
        4. Thresholding: Accept if confidence > learned threshold

    Returns:
        ProcedureMatch if confidence sufficient, else None
    """
    # Implementation deferred - multiple algorithms possible
    # (HMM, edit distance, constraint satisfaction, etc.)
    pass
```

**Deferred:** Exact matching algorithm specification. Phase 3 implementation will choose between:
- Hidden Markov Models (sequence probability)
- Edit distance (Levenshtein-style with step costs)
- Constraint satisfaction (flexible step ordering)

### Learned Parameters Schema

**Storage:** SQLite table

```sql
CREATE TABLE learned_parameters (
    procedure_id TEXT NOT NULL,
    participant_id TEXT NOT NULL,
    step_index INTEGER NOT NULL,

    -- Skip probability (0.0-1.0)
    skip_probability REAL DEFAULT 0.0,

    -- Duration statistics (minutes)
    duration_mean REAL,
    duration_variance REAL,

    -- Reordering allowance (steps can swap with neighbors)
    reorder_flexibility INTEGER DEFAULT 0,  -- 0=strict, 1=neighbor swap, 2=loose

    -- Location variations (JSON array of dwelling_point_ids)
    location_alternatives TEXT,  -- JSON: ["dp_123", "dp_456"]

    -- Substitution patterns (JSON: step_id that replaced this one)
    substitutions TEXT,

    -- Update metadata
    sample_count INTEGER DEFAULT 0,  -- How many observations contributed
    last_updated TEXT NOT NULL,      -- ISO 8601

    PRIMARY KEY (procedure_id, participant_id, step_index)
);
```

**Example Entry:**
```json
{
  "procedure_id": "act_morning_routine",
  "participant_id": "user_sarah",
  "step_index": 2,
  "skip_probability": 0.60,
  "duration_mean": 15.0,
  "duration_variance": 4.2,
  "reorder_flexibility": 1,
  "location_alternatives": ["dp_7a3f9b2c", "dp_gym_shower"],
  "sample_count": 47,
  "last_updated": "2025-06-15T10:00:00Z"
}
```

## Architecture: Correction Feedback Loop

### Correction Event Schema

**Storage:** Unified Event Log (alongside `action_detected`, `participant_response`)

```rust
pub struct ProcedureCorrectionEvent {
    pub event_id: String,              // Unique event ID
    pub timestamp: String,             // ISO 8601
    pub source: String,                // Always "participant"
    pub event_type: String,            // Always "procedure_correction"

    pub payload: CorrectionPayload,
}

pub struct CorrectionPayload {
    pub match_id: String,              // References ProcedureMatch that was corrected
    pub original_procedure_id: String, // What system inferred
    pub correction_type: CorrectionType,
    pub correct_procedure_id: Option<String>,  // If type is WrongProcedure
    pub participant_note: Option<String>,      // Free-text explanation
}

pub enum CorrectionType {
    Confirmed,          // "Yes, that's right"
    WrongProcedure,     // "No, I was doing X not Y"
    PartialMatch,       // "Sort of - I modified it"
    Rejected,           // "No, that didn't happen"
}
```

**Contract:** Each correction MUST reference a valid `match_id` from a previous procedure match. System MUST validate correction before updating learned parameters.

### Learning Update Algorithm

```python
def update_learned_parameters(correction: ProcedureCorrectionEvent,
                              original_match: ProcedureMatch):
    """
    Update SQLite learned_parameters based on participant correction.

    Learning rules:
        - Confirmed: Strengthen matched pattern, increase confidence
        - WrongProcedure: Penalize false positive, relax matching strictness
        - PartialMatch: Analyze which steps matched/missed, update skip probabilities
        - Rejected: Strong penalty, may indicate template-participant mismatch

    Update strategy: Exponential moving average with learning rate α=0.1
        new_value = α * observed + (1-α) * old_value
    """
    if correction.correction_type == CorrectionType.Confirmed:
        # Strengthen all matched steps
        for step_idx in range(len(original_match.matched_events)):
            update_skip_probability(step_idx, decrease_by=0.05)
            update_duration_stats(step_idx, observed_duration)

    elif correction.correction_type == CorrectionType.WrongProcedure:
        # Penalize false positive - increase skip probabilities
        for step_idx in original_match.skipped_steps:
            update_skip_probability(step_idx, increase_by=0.10)

    # ... (other correction types)
```

**Contract:** Learning updates MUST be idempotent (reprocessing same correction produces same result) and reversible (participant can undo corrections).

## Integration Points

### Existing Schema Hooks

The redline system integrates through existing protocol elements:

**1. `procedure.steps` (`procedures.md`):**
- Provides template structure for matching
- Logical operators (`any_of`, `all_of`) indicate inherent flexibility
- Redline learns additional flexibility beyond template

**2. `interface.context_hints` (`action_interface.md`):**
- `typical_locations`: Redline resolves labels via DwellingPointLabel table
- `typical_time_of_day`: Redline learns actual participant patterns
- `confidence_threshold`: Redline adjusts per-participant

**3. Event Schemas:**
- `action_detected` events: Input for matching algorithm
- `participant_response` events: Source of correction feedback
- `procedure_correction` events: Explicit learning signal

**4. `parent_connections` (`intention_lattice.md`):**
- When redlines promoted to lattice, maintain connection to original template
- Enables tracking template evolution and community variations

## Lattice Promotion Mechanism

### Promotion Schema

**Trigger Conditions:**
```python
def should_suggest_promotion(procedure_id: str,
                            learned_params: LearnedParameters) -> bool:
    """
    Determine if redline is stable enough to promote to lattice.

    Criteria:
        - Sample count ≥ 30 (sufficient observations)
        - Learned pattern consistent (low variance in skip rates)
        - Participant has not recently corrected this procedure

    Returns:
        True if promotion should be suggested
    """
    return (
        learned_params.sample_count >= 30 and
        learned_params.pattern_stability > 0.80 and
        days_since_last_correction(procedure_id) > 14
    )
```

**Promoted Node Metadata:**
```toml
id = "act_my_morning_routine"
title = "My Morning Routine"
# Promotion tracking

promoted_from_redline = true
original_template = "act_morning_routine_template"
promoted_at = "2025-06-15T10:00:00Z"
promotion_confidence = 0.87 # Stability score from learned parameters

# Modified procedure incorporating learned variations
[procedure]
[[procedure.steps]]
type = "action"
id = "act_wake_up"

[[procedure.steps]]
type = "action"
id = "act_coffee"
duration_minutes = [ 12, 18,] # Learned: was [5, 10] in template
# Note: "shower" step removed - learned skip_probability=0.60
[[procedure.steps]]
type = "action"
id = "act_commute"
```

**Contract:** Promoted nodes MUST maintain `original_template` reference for:
- Template update merging
- Community learning attribution
- Version reconciliation

### Belief Network Sharing (Future)

**Deferred Details:**
- Privacy filtering (strip dwelling point IDs, replace with labels)
- Conflict resolution (multiple participants' variations of same template)
- Attribution (credit original template authors + variation contributors)

## Implementation Phases

### Phase 1: Static Label Mapping
- **Duration:** Months 1-2
- **Deliverable:** DwellingPointLabel table, onboarding UI
- **Contract:** `typical_locations` in templates resolve to participant dwelling points

### Phase 2: Correction Logging
- **Duration:** Months 3-4
- **Deliverable:** ProcedureCorrectionEvent schema, logging infrastructure
- **Contract:** All match attempts and corrections captured in event log

### Phase 3: Basic Adaptation
- **Duration:** Months 5-6
- **Deliverable:** LearnedParameters table, simple skip/duration learning
- **Contract:** Match confidence improves after 10+ corrections per procedure

### Phase 4: Advanced Features (Future)
- Sophisticated matching algorithms (HMM, edit distance)
- Lattice promotion UI
- Belief Network sharing infrastructure

## Open Questions

1. **Matching Algorithm:** Which approach (HMM, edit distance, constraint solver) best balances accuracy and performance?
2. **Confidence Calibration:** How to ensure confidence scores are well-calibrated probabilities (not just relative rankings)?
3. **Cold Start:** Minimum corrections needed before learning helps (vs. hurts)?
4. **Drift Detection:** How to recognize when participant's patterns fundamentally change (new job, moved, lifestyle shift)?
5. **Privacy Boundaries:** Which learned patterns are safe to share in Belief Networks?

## Design Principles

- **Explicit Contracts:** All data structures have formal schemas with validation rules
- **Participant as Ground Truth:** Corrections always override inference
- **Incremental Learning:** Small updates per correction, not batch retraining
- **Legible State:** Participant can inspect learned variations at any time
- **Reversibility:** Participant can reset to template defaults or undo promotions
- **Gradual Sophistication:** Start simple (label mapping), add complexity as needed

---

**Status:** This is a **placeholder design** establishing contracts and integration points. Algorithmic details (Phase 3+) deferred until implementation begins.
